{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example using Random Forest\n",
    "\n",
    "In this example we show how to apply different DCS and DES techniques for a classification dataset.\n",
    "\n",
    "A very important aspect in dynamic selection is the generation of a pool of classifiers. A common practice in the dynamic selection literature is to generate a pool of classifiers using the Bagging (Bootstrap Aggregating) method.\n",
    "\n",
    "In this example we generate a pool of classifiers using the Bagging technique implemented on the Scikit-learn library. Then, we compare the results obtained by combining this pool of classifiers using the standard Bagging combination approach versus the application of dynamic selection technique to select the set of most competent classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'DCS'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-70e3fc1d6878>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Example of DCS techniques\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mDCS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOLA\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOLA\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mDCS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAPriori\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAPriori\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mDCS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMCB\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMCB\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'DCS'"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Example of DCS techniques\n",
    "from DCS.OLA import OLA\n",
    "from DCS.APriori import APriori\n",
    "from DCS.MCB import MCB\n",
    "# Example of DES techniques\n",
    "from DES.KNORAE import KNORAE\n",
    "from DES.DESP import DESP\n",
    "from DES.KNORAU import KNORAU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a classification dataset and preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# split the data into training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "# Split the data into training and DSEL for DS techniques\n",
    "X_train, X_dsel, y_train, y_dsel = train_test_split(X_train, y_train, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Random Forest\n",
    "\n",
    "Here we generate a pool of classifiers using the Random Forest technique, which each base classifier is a decision tree classifier. The library works with any type of base classifier. The only requirement is that the base classifiers are able to estimate probabilities through the function (predict_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calibrating Perceptrons to estimate probabilities\n",
    "pool_classifiers = RandomForestClassifier(n_estimators=10)\n",
    "pool_classifiers.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing DS techniques\n",
    "\n",
    "Here we initialize the DS techniques. Three DCS and three DES techniques are considered in this example. In this example, we specify the size of the region of competence (k = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DES techniques\n",
    "knorau = KNORAU(pool_classifiers, k=5)\n",
    "kne = KNORAE(pool_classifiers, k=5)\n",
    "desp = DESP(pool_classifiers, k=5)\n",
    "# DCS techniques\n",
    "ola = OLA(pool_classifiers, k=5)\n",
    "mcb = MCB(pool_classifiers, k=5)\n",
    "apriori = APriori(pool_classifiers, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the DS techniques\n",
    "\n",
    "The function fit(data, target) is used to fit each dynamic selection method. The fit function prepares the algorithm that estimates the region of competence (e.g., K-NN algorithm) and pre-process information required to apply the DS techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knorau.fit(X_dsel, y_dsel)\n",
    "kne.fit(X_dsel, y_dsel)\n",
    "desp.fit(X_dsel, y_dsel)\n",
    "ola.fit(X_dsel, y_dsel)\n",
    "mcb.fit(X_dsel, y_dsel)\n",
    "apriori.fit(X_dsel, y_dsel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate classification accuracy of each technique\n",
    "\n",
    "In this case, the first result is the classification accuracy of the random forest classifier, which combines the outputs of each base decision tree using the majority voting scheme. \n",
    "\n",
    "Using DS techniques, instead of combining all decision trees, only the ones that are more competent locally are used for classification. In the case of DCS techniques, the decision tree that is most competent locally is used for prediction. In the case of DES techniques, an ensemble containing the most competent decision trees are selected to predict the label of a given query sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Classification accuracy of Random Forest: ', pool_classifiers.score(X_test, y_test))\n",
    "print('Classification accuracy of KNORA-Union: ', knorau.score(X_test, y_test))\n",
    "print('Classification accuracy of KNORA-Eliminate: ', kne.score(X_test, y_test))\n",
    "print('Classification accuracy of DESP: ', desp.score(X_test, y_test))\n",
    "print('Classification accuracy of OLA: ', ola.score(X_test, y_test))\n",
    "print('Classification accuracy of A priori: ', apriori.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
