{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example using an heterogeneous pool\n",
    "\n",
    "The library also support a heterogenous pool of classifiers. A pool is called heterogeneous when different classifier models are used to generate a diverse pool of classifiers (e.g., svm, decision tree, naive bayes...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'DCS'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-70e3fc1d6878>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Example of DCS techniques\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mDCS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOLA\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOLA\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mDCS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAPriori\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAPriori\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mDCS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMCB\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMCB\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'DCS'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Example of DCS techniques\n",
    "from DCS.OLA import OLA\n",
    "from DCS.APriori import APriori\n",
    "from DCS.MCB import MCB\n",
    "# Example of DES techniques\n",
    "from DES.KNORAE import KNORAE\n",
    "from DES.DESP import DESP\n",
    "from DES.KNORAU import KNORAU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a classification dataset and preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# split the data into training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "# Split the data into training and DSEL for DS techniques\n",
    "X_train, X_dsel, y_train, y_dsel = train_test_split(X_train, y_train, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an heterogeneous pool of classifiers\n",
    "\n",
    "In this example we train a pool composed of:\n",
    "1 - Perceptron classifier\n",
    "2 - Linear SVM\n",
    "3 - Gaussian SVM\n",
    "4 - Naive Bayes\n",
    "5 - Decision tree\n",
    "6 - 1NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.trees import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "model_perceptron = CalibratedClassifierCV(Perceptron(), cv=3, method='sigmoid').fit(X_train, y_train)\n",
    "model_linear_svm = LinearSVC(probability=True).fit(X_train, y_train)\n",
    "model_svc = SVC(probability=True).fit(X_train, y_train)\n",
    "model_bayes = GaussianNB().fit(X_train, y_train)\n",
    "model_bayes2 = MultinomialNB().fit(X_train, y_train)\n",
    "model_tree = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "model_knn = KNeighborsClassifier(k=1).fit(X_train, y_train)\n",
    "pool_classifiers = [model_perceptron, model_linear_svm, model_svc, model_bayes, model_bayes2, model_tree, model_knn]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing DS techniques\n",
    "\n",
    "Here we initialize the DS techniques. Three DCS and three DES techniques are considered in this example. In this example, we specify the size of the region of competence (k = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DES techniques\n",
    "knorau = KNORAU(pool_classifiers, k=5)\n",
    "kne = KNORAE(pool_classifiers, k=5)\n",
    "desp = DESP(pool_classifiers, k=5)\n",
    "# DCS techniques\n",
    "ola = OLA(pool_classifiers, k=5)\n",
    "mcb = MCB(pool_classifiers, k=5)\n",
    "apriori = APriori(pool_classifiers, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the DS techniques\n",
    "\n",
    "The function fit(data, target) is used to fit each dynamic selection method. The fit function prepares the algorithm that estimates the region of competence (e.g., K-NN algorithm) and pre-process information required to apply the DS techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knorau.fit(X_dsel, y_dsel)\n",
    "kne.fit(X_dsel, y_dsel)\n",
    "desp.fit(X_dsel, y_dsel)\n",
    "ola.fit(X_dsel, y_dsel)\n",
    "mcb.fit(X_dsel, y_dsel)\n",
    "apriori.fit(X_dsel, y_dsel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate classification accuracy of each technique\n",
    "\n",
    "In this case, the first result is the classification accuracy of the random forest classifier, which combines the outputs of each base decision tree using the majority voting scheme. \n",
    "\n",
    "Using DS techniques, instead of combining all decision trees, only the ones that are more competent locally are used for classification. In the case of DCS techniques, the decision tree that is most competent locally is used for prediction. In the case of DES techniques, an ensemble containing the most competent decision trees are selected to predict the label of a given query sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Classification accuracy of Majority voting the pool: ', pool_classifiers.score(X_test, y_test))\n",
    "print('Classification accuracy of KNORA-Union: ', knorau.score(X_test, y_test))\n",
    "print('Classification accuracy of KNORA-Eliminate: ', kne.score(X_test, y_test))\n",
    "print('Classification accuracy of DESP: ', desp.score(X_test, y_test))\n",
    "print('Classification accuracy of OLA: ', ola.score(X_test, y_test))\n",
    "print('Classification accuracy of A priori: ', apriori.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}